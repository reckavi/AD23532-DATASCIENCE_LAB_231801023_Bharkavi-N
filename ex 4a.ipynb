{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c925a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tcs\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tcs\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: click in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tcs\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29ce7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tcs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3a168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a9b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 'Text' column and remove nulls\n",
    "df_reviews = df[['Text']].dropna()\n",
    "\n",
    "# Limit to 10,000 reviews\n",
    "df_reviews = df_reviews.head(10000)\n",
    "\n",
    "df_reviews.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3903844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69788a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # a. Lowercase\n",
    "    text = text.lower()\n",
    "    # b. Remove punctuation/special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # c. Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # d. Remove stopwords\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    # e. Join tokens back\n",
    "    return ' '.join(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb96a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['cleaned_text'] = df_reviews['Text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a97ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df_reviews['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22cb456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_reviews(query, top_k=5):\n",
    "    # a. Preprocess query\n",
    "    cleaned_query = preprocess_text(query)\n",
    "    # b. Convert to vector\n",
    "    query_vec = vectorizer.transform([cleaned_query])\n",
    "    # c. Compute similarity\n",
    "    similarity_scores = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    # d. Get top k\n",
    "    top_indices = similarity_scores.argsort()[-top_k:][::-1]\n",
    "    # e. Return original + cleaned reviews\n",
    "    return df_reviews.iloc[top_indices][['Text', 'cleaned_text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ce1360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'great product with fast shipping'\n",
      "                                                   Text  \\\n",
      "5226  Enjoyed the product and they also provided ver...   \n",
      "8021  The tea is good and fresh. We enjoy it. The sh...   \n",
      "7073  My daughter lives in Hawaii and sent me some g...   \n",
      "6034  The energy drink is a great product. The shipp...   \n",
      "9878  Fast shipping, items were packaged nicely and ...   \n",
      "\n",
      "                                           cleaned_text  \n",
      "5226  enjoyed product also provided fast shipping im...  \n",
      "8021  tea good fresh enjoy shipping fast cost reason...  \n",
      "7073  daughter lives hawaii sent great coffee keurig...  \n",
      "6034  energy drink great product shipping price craz...  \n",
      "9878  fast shipping items packaged nicely described ...  \n",
      "\n",
      "üîç Query: 'disappointed'\n",
      "                                                   Text  \\\n",
      "3151  I am a bit disappointed.  The flavor was not w...   \n",
      "4378  The product is very good. Way too expensive an...   \n",
      "6548  Disappointed.  The big boxes had a very differ...   \n",
      "3333  Just plain nasty!!! This item tasted like card...   \n",
      "8004  this stuff really works, i love it and cant ge...   \n",
      "\n",
      "                                           cleaned_text  \n",
      "3151            bit disappointed flavor wanted expected  \n",
      "4378  product good way expensive almost box get panc...  \n",
      "6548  disappointed big boxes different flavor smalle...  \n",
      "3333  plain nasty item tasted like cardboard watered...  \n",
      "8004  stuff really works love cant get enough tastes...  \n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "print(\"üîç Query: 'great product with fast shipping'\")\n",
    "print(retrieve_reviews(\"great product with fast shipping\"))\n",
    "\n",
    "# Example 2\n",
    "print(\"\\nüîç Query: 'disappointed'\")\n",
    "print(retrieve_reviews(\"disappointed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c22c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
